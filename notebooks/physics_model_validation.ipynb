{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf61b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Could not find src directory. CWD: /content\n",
      "  Please ensure you're using the correct Python kernel.\n",
      "  Current Python: /usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "# Setup: Configure environment for SMPS\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Determine environment\n",
    "cwd = Path.cwd()\n",
    "is_cloud = cwd == Path('/content') or 'google.colab' in sys.modules\n",
    "\n",
    "if is_cloud:\n",
    "    print(\"‚òÅÔ∏è  Running in cloud environment (Colab)\")\n",
    "\n",
    "    # Check if SMPS already exists\n",
    "    smps_path = Path('/content/SMPS')\n",
    "    if not smps_path.exists():\n",
    "        print(\"Cloning SMPS repository...\")\n",
    "        # For private repo, you'd need to authenticate\n",
    "        # For now, we'll create a minimal setup\n",
    "        smps_path.mkdir(parents=True, exist_ok=True)\n",
    "        (smps_path / 'src').mkdir(exist_ok=True)\n",
    "        print(\"‚ö†Ô∏è  SMPS source not available in cloud.\")\n",
    "        print(\"   Please upload the 'src/smps' directory to /content/SMPS/src/\")\n",
    "        print(\"   Or run this notebook locally with: Python (SMPS) kernel\")\n",
    "\n",
    "    src_path = smps_path / 'src'\n",
    "    if src_path.exists():\n",
    "        sys.path.insert(0, str(src_path))\n",
    "        print(f\"‚úì Added to path: {src_path}\")\n",
    "else:\n",
    "    print(\"üíª Running locally\")\n",
    "    # Try to find src directory\n",
    "    possible_src_paths = [\n",
    "        Path('/home/viv/SMPS/src'),\n",
    "        cwd.parent / 'src',\n",
    "        cwd / 'src',\n",
    "    ]\n",
    "\n",
    "    for src_path in possible_src_paths:\n",
    "        if src_path.exists() and (src_path / 'smps').exists():\n",
    "            if str(src_path) not in sys.path:\n",
    "                sys.path.insert(0, str(src_path))\n",
    "            print(f\"‚úì Added to path: {src_path}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"‚ö† Could not find src directory\")\n",
    "        print(f\"  Python: {sys.executable}\")\n",
    "\n",
    "# Verify import\n",
    "try:\n",
    "    import smps\n",
    "    print(f\"‚úì SMPS version: {getattr(smps, '__version__', 'unknown')}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚úó Cannot import smps: {e}\")\n",
    "    print(\"\\nTo run this notebook:\")\n",
    "    print(\"1. Locally: Select 'Python (SMPS)' kernel from VS Code\")\n",
    "    print(\"2. Cloud: Upload src/smps directory to /content/SMPS/src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b49cbfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'smps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-624718608.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# SMPS imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwater_balance\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTwoBucketWaterBalance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_two_bucket_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphysics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpedotransfer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimate_soil_parameters_saxton\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweather\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenMeteoSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'smps'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# SMPS imports\n",
    "from smps.physics.water_balance import TwoBucketWaterBalance, ModelParameters, create_two_bucket_model\n",
    "from smps.physics.pedotransfer import estimate_soil_parameters_saxton\n",
    "from smps.data.sources.weather import OpenMeteoSource\n",
    "from smps.data.sources.soil import SoilGridsSource, MockSoilSource\n",
    "from smps.data.sources.isda import IsdaAfricaSoilSource\n",
    "from smps.data.sources.satellite import MODISNDVISource\n",
    "from smps.data.sources.base import DataFetchRequest\n",
    "from smps.core.types import SiteMetadata, SoilParameters\n",
    "from smps.validation import ValidationEngine, ValidationMetrics, print_metrics_comparison\n",
    "\n",
    "# Set up logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "print(\"‚úì All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde23e5c",
   "metadata": {},
   "source": [
    "## 1. Define Test Sites with Geocoordinates\n",
    "\n",
    "We'll use several test sites across Africa with known agricultural activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test sites with geocoordinates\n",
    "TEST_SITES = {\n",
    "    \"tunisia_sfax\": {\n",
    "        \"latitude\": 34.740,\n",
    "        \"longitude\": 10.760,\n",
    "        \"elevation_m\": 50,\n",
    "        \"description\": \"Semi-arid agricultural zone in Tunisia\",\n",
    "        \"crop_type\": \"olive\",\n",
    "        \"soil_expected\": \"Sandy loam\"\n",
    "    },\n",
    "    \"kenya_eldoret\": {\n",
    "        \"latitude\": 0.5143,\n",
    "        \"longitude\": 35.2698,\n",
    "        \"elevation_m\": 2100,\n",
    "        \"description\": \"Highland agricultural zone in Kenya\",\n",
    "        \"crop_type\": \"maize\",\n",
    "        \"soil_expected\": \"Clay loam\"\n",
    "    },\n",
    "    \"ghana_kumasi\": {\n",
    "        \"latitude\": 6.6885,\n",
    "        \"longitude\": -1.6244,\n",
    "        \"elevation_m\": 270,\n",
    "        \"description\": \"Humid tropical zone in Ghana\",\n",
    "        \"crop_type\": \"cocoa\",\n",
    "        \"soil_expected\": \"Clay\"\n",
    "    },\n",
    "    \"ethiopia_addis\": {\n",
    "        \"latitude\": 9.0320,\n",
    "        \"longitude\": 38.7497,\n",
    "        \"elevation_m\": 2355,\n",
    "        \"description\": \"Ethiopian highlands\",\n",
    "        \"crop_type\": \"teff\",\n",
    "        \"soil_expected\": \"Vertisol (clay)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display sites\n",
    "sites_df = pd.DataFrame(TEST_SITES).T\n",
    "sites_df.index.name = 'site_id'\n",
    "print(\"Test Sites:\")\n",
    "display(sites_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f07f8",
   "metadata": {},
   "source": [
    "## 2. Fetch Soil Data (iSDA Africa / SoilGrids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dd7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_soil_data(site_id: str, lat: float, lon: float):\n",
    "    \"\"\"Fetch soil data from iSDA or SoilGrids\"\"\"\n",
    "\n",
    "    # Try iSDA first for Africa\n",
    "    try:\n",
    "        isda_source = IsdaAfricaSoilSource()\n",
    "        profile = isda_source.fetch_soil_profile(site_id, latitude=lat, longitude=lon)\n",
    "        print(f\"‚úì Fetched from iSDA Africa\")\n",
    "        return profile, \"isda\"\n",
    "    except Exception as e:\n",
    "        print(f\"iSDA failed: {e}\")\n",
    "\n",
    "    # Fallback to SoilGrids\n",
    "    try:\n",
    "        soilgrids_source = SoilGridsSource()\n",
    "        profile = soilgrids_source.fetch_soil_profile(site_id)\n",
    "        print(f\"‚úì Fetched from SoilGrids\")\n",
    "        return profile, \"soilgrids\"\n",
    "    except Exception as e:\n",
    "        print(f\"SoilGrids failed: {e}\")\n",
    "\n",
    "    # Final fallback: Mock data\n",
    "    mock_source = MockSoilSource()\n",
    "    profile = mock_source.fetch_soil_profile(site_id)\n",
    "    print(f\"‚ö† Using mock soil data\")\n",
    "    return profile, \"mock\"\n",
    "\n",
    "# Fetch soil data for all sites\n",
    "soil_profiles = {}\n",
    "\n",
    "for site_id, site_info in TEST_SITES.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Site: {site_id}\")\n",
    "    print(f\"Location: ({site_info['latitude']}, {site_info['longitude']})\")\n",
    "\n",
    "    profile, source = fetch_soil_data(\n",
    "        site_id,\n",
    "        site_info['latitude'],\n",
    "        site_info['longitude']\n",
    "    )\n",
    "    soil_profiles[site_id] = profile\n",
    "\n",
    "    print(f\"\\nSoil Properties:\")\n",
    "    print(f\"  Sand: {profile.sand_percent:.1f}%\")\n",
    "    print(f\"  Clay: {profile.clay_percent:.1f}%\")\n",
    "    print(f\"  Silt: {profile.silt_percent:.1f}%\")\n",
    "    print(f\"  Porosity: {profile.porosity:.3f}\")\n",
    "    print(f\"  Field Capacity: {profile.field_capacity:.3f}\")\n",
    "    print(f\"  Wilting Point: {profile.wilting_point:.3f}\")\n",
    "    print(f\"  Ksat: {profile.saturated_hydraulic_conductivity_cm_day:.1f} cm/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859f4cc",
   "metadata": {},
   "source": [
    "## 3. Fetch Weather Data (Open-Meteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf0004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define analysis period\n",
    "START_DATE = date(2023, 1, 1)\n",
    "END_DATE = date(2023, 12, 31)\n",
    "\n",
    "print(f\"Analysis period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Duration: {(END_DATE - START_DATE).days + 1} days\")\n",
    "\n",
    "def fetch_weather_data(site_id: str, lat: float, lon: float,\n",
    "                       start_date: date, end_date: date):\n",
    "    \"\"\"Fetch weather data from Open-Meteo\"\"\"\n",
    "\n",
    "    weather_source = OpenMeteoSource()\n",
    "\n",
    "    # Create request\n",
    "    request = DataFetchRequest(\n",
    "        site_id=site_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        parameters={\"include_forecast\": False}\n",
    "    )\n",
    "\n",
    "    # Override site coordinates\n",
    "    weather_source._get_site_coordinates = lambda s: (lat, lon)\n",
    "\n",
    "    try:\n",
    "        weather_data = weather_source.fetch_daily_weather(request)\n",
    "        print(f\"‚úì Fetched {len(weather_data)} days of weather data\")\n",
    "        return weather_data\n",
    "    except Exception as e:\n",
    "        print(f\"Weather fetch failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Fetch weather for all sites\n",
    "weather_data = {}\n",
    "\n",
    "for site_id, site_info in TEST_SITES.items():\n",
    "    print(f\"\\nFetching weather for {site_id}...\")\n",
    "    weather = fetch_weather_data(\n",
    "        site_id,\n",
    "        site_info['latitude'],\n",
    "        site_info['longitude'],\n",
    "        START_DATE,\n",
    "        END_DATE\n",
    "    )\n",
    "    weather_data[site_id] = weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3394b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weather data to DataFrames for analysis\n",
    "weather_dfs = {}\n",
    "\n",
    "for site_id, data in weather_data.items():\n",
    "    if data:\n",
    "        df = pd.DataFrame([d.dict() for d in data])\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.set_index('date').sort_index()\n",
    "        weather_dfs[site_id] = df\n",
    "\n",
    "        # Quick summary\n",
    "        print(f\"\\n{site_id}:\")\n",
    "        print(f\"  Total precipitation: {df['precipitation_mm'].sum():.1f} mm\")\n",
    "        print(f\"  Total ET0: {df['et0_mm'].sum():.1f} mm\")\n",
    "        print(f\"  Mean temperature: {df['temperature_mean_c'].mean():.1f}¬∞C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3eb79",
   "metadata": {},
   "source": [
    "## 4. Fetch Satellite NDVI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f96ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ndvi_data(site_id: str, lat: float, lon: float,\n",
    "                    start_date: date, end_date: date):\n",
    "    \"\"\"Fetch NDVI data from MODIS\"\"\"\n",
    "\n",
    "    ndvi_source = MODISNDVISource()\n",
    "\n",
    "    # Override coordinates\n",
    "    ndvi_source._get_site_coordinates = lambda s: (lat, lon)\n",
    "\n",
    "    request = DataFetchRequest(\n",
    "        site_id=site_id,\n",
    "        start_date=start_date,\n",
    "        end_date=end_date\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result = ndvi_source.fetch(request)\n",
    "        print(f\"‚úì Fetched {len(result.data)} NDVI observations (source: {result.metadata.get('source', 'unknown')})\")\n",
    "        return result.data\n",
    "    except Exception as e:\n",
    "        print(f\"NDVI fetch failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# Fetch NDVI for all sites\n",
    "ndvi_data = {}\n",
    "\n",
    "for site_id, site_info in TEST_SITES.items():\n",
    "    print(f\"\\nFetching NDVI for {site_id}...\")\n",
    "    ndvi = fetch_ndvi_data(\n",
    "        site_id,\n",
    "        site_info['latitude'],\n",
    "        site_info['longitude'],\n",
    "        START_DATE,\n",
    "        END_DATE\n",
    "    )\n",
    "    ndvi_data[site_id] = ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50611630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NDVI to DataFrames\n",
    "ndvi_dfs = {}\n",
    "\n",
    "for site_id, data in ndvi_data.items():\n",
    "    if data:\n",
    "        df = pd.DataFrame([d.dict() for d in data])\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.set_index('date').sort_index()\n",
    "        ndvi_dfs[site_id] = df\n",
    "\n",
    "        print(f\"{site_id}: NDVI range [{df['ndvi'].min():.3f}, {df['ndvi'].max():.3f}], mean={df['ndvi'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a50e18",
   "metadata": {},
   "source": [
    "## 5. Build Canonical Data Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ca79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_canonical_table(site_id: str, weather_df: pd.DataFrame,\n",
    "                          ndvi_df: pd.DataFrame, soil_profile) -> pd.DataFrame:\n",
    "    \"\"\"Build canonical daily table from all data sources\"\"\"\n",
    "\n",
    "    # Start with weather data\n",
    "    canonical = weather_df.copy()\n",
    "\n",
    "    # Add NDVI\n",
    "    if 'ndvi' in ndvi_df.columns:\n",
    "        canonical = canonical.join(ndvi_df[['ndvi', 'evi']], how='left')\n",
    "\n",
    "    # Forward fill missing NDVI (16-day composite)\n",
    "    canonical['ndvi'] = canonical['ndvi'].ffill().bfill()\n",
    "    if 'evi' in canonical.columns:\n",
    "        canonical['evi'] = canonical['evi'].ffill().bfill()\n",
    "\n",
    "    # Add static soil properties\n",
    "    canonical['sand_percent'] = soil_profile.sand_percent\n",
    "    canonical['clay_percent'] = soil_profile.clay_percent\n",
    "    canonical['porosity'] = soil_profile.porosity\n",
    "    canonical['field_capacity'] = soil_profile.field_capacity\n",
    "    canonical['wilting_point'] = soil_profile.wilting_point\n",
    "\n",
    "    # Calculate derived features\n",
    "    canonical['precip_cumsum_7d'] = canonical['precipitation_mm'].rolling(7).sum()\n",
    "    canonical['et0_cumsum_7d'] = canonical['et0_mm'].rolling(7).sum()\n",
    "    canonical['water_balance_7d'] = canonical['precip_cumsum_7d'] - canonical['et0_cumsum_7d']\n",
    "\n",
    "    # Antecedent conditions\n",
    "    canonical['precip_1d_lag'] = canonical['precipitation_mm'].shift(1)\n",
    "    canonical['precip_3d_sum'] = canonical['precipitation_mm'].rolling(3).sum()\n",
    "\n",
    "    return canonical\n",
    "\n",
    "# Build canonical tables for all sites\n",
    "canonical_tables = {}\n",
    "\n",
    "for site_id in TEST_SITES.keys():\n",
    "    if site_id in weather_dfs and site_id in ndvi_dfs:\n",
    "        canonical = build_canonical_table(\n",
    "            site_id,\n",
    "            weather_dfs[site_id],\n",
    "            ndvi_dfs[site_id],\n",
    "            soil_profiles[site_id]\n",
    "        )\n",
    "        canonical_tables[site_id] = canonical\n",
    "        print(f\"‚úì Built canonical table for {site_id}: {len(canonical)} rows, {len(canonical.columns)} columns\")\n",
    "\n",
    "# Show sample\n",
    "print(\"\\nSample canonical table (tunisia_sfax):\")\n",
    "display(canonical_tables['tunisia_sfax'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4daccd5",
   "metadata": {},
   "source": [
    "## 6. Run Physics Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_physics_model(canonical_df: pd.DataFrame, soil_profile) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run the two-bucket water balance model.\n",
    "\n",
    "    Returns DataFrame with physics-based soil moisture predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create soil parameters\n",
    "    soil_params = SoilParameters(\n",
    "        sand_percent=soil_profile.sand_percent,\n",
    "        silt_percent=soil_profile.silt_percent,\n",
    "        clay_percent=soil_profile.clay_percent,\n",
    "        porosity=soil_profile.porosity,\n",
    "        field_capacity=soil_profile.field_capacity,\n",
    "        wilting_point=soil_profile.wilting_point,\n",
    "        saturated_hydraulic_conductivity_cm_day=soil_profile.saturated_hydraulic_conductivity_cm_day\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = create_two_bucket_model(soil_params)\n",
    "\n",
    "    # Run simulation\n",
    "    results = []\n",
    "\n",
    "    for idx, row in canonical_df.iterrows():\n",
    "        # Handle missing values\n",
    "        precip = row['precipitation_mm'] if pd.notna(row['precipitation_mm']) else 0.0\n",
    "        et0 = row['et0_mm'] if pd.notna(row['et0_mm']) else 3.0  # Default ET0\n",
    "        ndvi = row.get('ndvi', 0.5) if pd.notna(row.get('ndvi', np.nan)) else 0.5\n",
    "\n",
    "        # Run daily step\n",
    "        try:\n",
    "            result = model.run_daily(\n",
    "                precipitation_mm=precip,\n",
    "                et0_mm=et0,\n",
    "                ndvi=ndvi,\n",
    "                check_water_balance=True\n",
    "            )\n",
    "\n",
    "            results.append({\n",
    "                'date': idx,\n",
    "                'theta_surface': result.theta_surface,\n",
    "                'theta_root': result.theta_root,\n",
    "                'evaporation': result.fluxes.get('evaporation', 0),\n",
    "                'transpiration': result.fluxes.get('transpiration', 0),\n",
    "                'evapotranspiration': result.fluxes.get('evapotranspiration', 0),\n",
    "                'drainage': result.fluxes.get('drainage', 0),\n",
    "                'runoff': result.fluxes.get('runoff', 0),\n",
    "                'infiltration': result.fluxes.get('infiltration', 0),\n",
    "                'water_balance_error': result.water_balance_error\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {idx}: {e}\")\n",
    "            results.append({\n",
    "                'date': idx,\n",
    "                'theta_surface': np.nan,\n",
    "                'theta_root': np.nan\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results).set_index('date')\n",
    "    return results_df\n",
    "\n",
    "# Run physics model for all sites\n",
    "physics_results = {}\n",
    "\n",
    "for site_id, canonical in canonical_tables.items():\n",
    "    print(f\"\\nRunning physics model for {site_id}...\")\n",
    "    results = run_physics_model(canonical, soil_profiles[site_id])\n",
    "    physics_results[site_id] = results\n",
    "\n",
    "    # Summary statistics\n",
    "    print(f\"  Surface SM: mean={results['theta_surface'].mean():.3f}, range=[{results['theta_surface'].min():.3f}, {results['theta_surface'].max():.3f}]\")\n",
    "    print(f\"  Root SM: mean={results['theta_root'].mean():.3f}, range=[{results['theta_root'].min():.3f}, {results['theta_root'].max():.3f}]\")\n",
    "    print(f\"  Water balance error: mean={results['water_balance_error'].abs().mean():.6f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc3eda8",
   "metadata": {},
   "source": [
    "## 7. Generate Reference Data (Synthetic Observations)\n",
    "\n",
    "Since we don't have actual field measurements, we'll generate synthetic \"observed\" data based on:\n",
    "- Physics model output with added noise\n",
    "- Plausible sensor measurement errors\n",
    "- Some systematic bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_observations(physics_df: pd.DataFrame,\n",
    "                                    soil_profile,\n",
    "                                    noise_std: float = 0.03,\n",
    "                                    bias: float = 0.0,\n",
    "                                    missing_fraction: float = 0.1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic soil moisture observations.\n",
    "\n",
    "    This simulates what we might get from:\n",
    "    - In-situ sensors with measurement noise\n",
    "    - Satellite soil moisture products (SMAP, SMOS)\n",
    "    - GRAFS model outputs\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Reproducibility\n",
    "\n",
    "    obs = pd.DataFrame(index=physics_df.index)\n",
    "\n",
    "    # Surface observations (like satellite retrievals)\n",
    "    obs['sm_obs_surface'] = (\n",
    "        physics_df['theta_surface']\n",
    "        + np.random.normal(bias, noise_std, len(physics_df))\n",
    "    )\n",
    "\n",
    "    # Root zone observations (like sensor measurements)\n",
    "    obs['sm_obs_root'] = (\n",
    "        physics_df['theta_root']\n",
    "        + np.random.normal(bias * 0.5, noise_std * 0.8, len(physics_df))\n",
    "    )\n",
    "\n",
    "    # Clip to physical limits\n",
    "    wp = soil_profile.wilting_point\n",
    "    por = soil_profile.porosity\n",
    "    obs['sm_obs_surface'] = obs['sm_obs_surface'].clip(wp, por)\n",
    "    obs['sm_obs_root'] = obs['sm_obs_root'].clip(wp, por)\n",
    "\n",
    "    # Add some missing values\n",
    "    mask = np.random.random(len(obs)) < missing_fraction\n",
    "    obs.loc[mask, 'sm_obs_surface'] = np.nan\n",
    "\n",
    "    return obs\n",
    "\n",
    "# Generate observations for all sites\n",
    "observations = {}\n",
    "\n",
    "for site_id, physics_df in physics_results.items():\n",
    "    obs = generate_synthetic_observations(\n",
    "        physics_df,\n",
    "        soil_profiles[site_id],\n",
    "        noise_std=0.035,\n",
    "        bias=0.01,\n",
    "        missing_fraction=0.15\n",
    "    )\n",
    "    observations[site_id] = obs\n",
    "    print(f\"{site_id}: Generated {(~obs['sm_obs_surface'].isna()).sum()} surface obs, {(~obs['sm_obs_root'].isna()).sum()} root obs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec557e3",
   "metadata": {},
   "source": [
    "## 8. Compute Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33376c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize validation engine\n",
    "validator = ValidationEngine(min_samples=10)\n",
    "\n",
    "# Compute metrics for all sites\n",
    "all_metrics = {}\n",
    "\n",
    "for site_id in physics_results.keys():\n",
    "    physics = physics_results[site_id]\n",
    "    obs = observations[site_id]\n",
    "\n",
    "    # Surface layer metrics\n",
    "    surface_metrics = validator.compute_metrics(\n",
    "        obs['sm_obs_surface'].values,\n",
    "        physics['theta_surface'].values\n",
    "    )\n",
    "\n",
    "    # Root zone metrics\n",
    "    root_metrics = validator.compute_metrics(\n",
    "        obs['sm_obs_root'].values,\n",
    "        physics['theta_root'].values\n",
    "    )\n",
    "\n",
    "    all_metrics[site_id] = {\n",
    "        'surface': surface_metrics,\n",
    "        'root': root_metrics\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Site: {site_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nSurface Layer (0-10cm):\")\n",
    "    print(surface_metrics.summary())\n",
    "    print(f\"\\nRoot Zone (10-40cm):\")\n",
    "    print(root_metrics.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c57368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table of all metrics\n",
    "summary_data = []\n",
    "\n",
    "for site_id, metrics in all_metrics.items():\n",
    "    for layer, m in metrics.items():\n",
    "        summary_data.append({\n",
    "            'Site': site_id,\n",
    "            'Layer': layer,\n",
    "            'RMSE': m.rmse,\n",
    "            'MAE': m.mae,\n",
    "            'Bias': m.bias,\n",
    "            'R¬≤': m.r_squared,\n",
    "            'NSE': m.nse,\n",
    "            'KGE': m.kge,\n",
    "            'N': m.n_valid\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\nValidation Metrics Summary:\")\n",
    "display(summary_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d3fc1",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac652dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series for each site\n",
    "fig, axes = plt.subplots(len(TEST_SITES), 2, figsize=(16, 4*len(TEST_SITES)))\n",
    "\n",
    "for i, (site_id, site_info) in enumerate(TEST_SITES.items()):\n",
    "    physics = physics_results[site_id]\n",
    "    obs = observations[site_id]\n",
    "    canonical = canonical_tables[site_id]\n",
    "\n",
    "    # Left: Surface soil moisture\n",
    "    ax1 = axes[i, 0]\n",
    "    ax1.plot(physics.index, physics['theta_surface'], 'b-', label='Physics Model', alpha=0.8)\n",
    "    ax1.scatter(obs.index, obs['sm_obs_surface'], c='r', s=10, alpha=0.5, label='Observations')\n",
    "    ax1.axhline(y=soil_profiles[site_id].field_capacity, color='g', linestyle='--', alpha=0.5, label='Field Capacity')\n",
    "    ax1.axhline(y=soil_profiles[site_id].wilting_point, color='orange', linestyle='--', alpha=0.5, label='Wilting Point')\n",
    "    ax1.set_ylabel('VWC (m¬≥/m¬≥)')\n",
    "    ax1.set_title(f'{site_id} - Surface Layer (0-10cm)')\n",
    "    if i == 0:\n",
    "        ax1.legend(loc='upper right')\n",
    "    ax1.set_ylim(0, 0.6)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add precipitation bars\n",
    "    ax1_twin = ax1.twinx()\n",
    "    ax1_twin.bar(canonical.index, canonical['precipitation_mm'], alpha=0.2, color='blue', width=1)\n",
    "    ax1_twin.set_ylabel('Precip (mm)', color='blue')\n",
    "    ax1_twin.set_ylim(0, 100)\n",
    "    ax1_twin.invert_yaxis()\n",
    "\n",
    "    # Right: Root zone soil moisture\n",
    "    ax2 = axes[i, 1]\n",
    "    ax2.plot(physics.index, physics['theta_root'], 'b-', label='Physics Model', alpha=0.8)\n",
    "    ax2.scatter(obs.index, obs['sm_obs_root'], c='r', s=10, alpha=0.5, label='Observations')\n",
    "    ax2.axhline(y=soil_profiles[site_id].field_capacity, color='g', linestyle='--', alpha=0.5)\n",
    "    ax2.axhline(y=soil_profiles[site_id].wilting_point, color='orange', linestyle='--', alpha=0.5)\n",
    "    ax2.set_ylabel('VWC (m¬≥/m¬≥)')\n",
    "    ax2.set_title(f'{site_id} - Root Zone (10-40cm)')\n",
    "    ax2.set_ylim(0, 0.6)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add metrics annotation\n",
    "    m = all_metrics[site_id]['root']\n",
    "    ax2.text(0.98, 0.95, f'R¬≤={m.r_squared:.3f}\\nRMSE={m.rmse:.3f}\\nNSE={m.nse:.3f}',\n",
    "             transform=ax2.transAxes, ha='right', va='top', fontsize=9,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/features/validation_timeseries.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved validation_timeseries.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2378f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: Predicted vs Observed\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "for i, (site_id, site_info) in enumerate(TEST_SITES.items()):\n",
    "    physics = physics_results[site_id]\n",
    "    obs = observations[site_id]\n",
    "\n",
    "    # Surface layer\n",
    "    ax1 = axes[0, 0] if i < 2 else axes[0, 1]\n",
    "    mask = ~obs['sm_obs_surface'].isna()\n",
    "    ax1.scatter(obs.loc[mask, 'sm_obs_surface'], physics.loc[mask, 'theta_surface'],\n",
    "                c=[colors[i]], alpha=0.3, s=10, label=site_id)\n",
    "\n",
    "    # Root zone\n",
    "    ax2 = axes[1, 0] if i < 2 else axes[1, 1]\n",
    "    mask = ~obs['sm_obs_root'].isna()\n",
    "    ax2.scatter(obs.loc[mask, 'sm_obs_root'], physics.loc[mask, 'theta_root'],\n",
    "                c=[colors[i]], alpha=0.3, s=10, label=site_id)\n",
    "\n",
    "# Add 1:1 lines and labels\n",
    "for ax in axes.flat:\n",
    "    lims = [0.05, 0.55]\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.5, label='1:1 line')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.set_xlabel('Observed VWC (m¬≥/m¬≥)')\n",
    "    ax.set_ylabel('Predicted VWC (m¬≥/m¬≥)')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "axes[0, 0].set_title('Surface Layer - Sites 1-2')\n",
    "axes[0, 1].set_title('Surface Layer - Sites 3-4')\n",
    "axes[1, 0].set_title('Root Zone - Sites 1-2')\n",
    "axes[1, 1].set_title('Root Zone - Sites 3-4')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/features/validation_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved validation_scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of metrics across sites\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "metrics_to_plot = ['RMSE', 'MAE', 'R¬≤', 'NSE', 'KGE', 'Bias']\n",
    "sites = list(TEST_SITES.keys())\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes.flat[i]\n",
    "\n",
    "    surface_vals = [summary_df[(summary_df['Site']==s) & (summary_df['Layer']=='surface')][metric].values[0] for s in sites]\n",
    "    root_vals = [summary_df[(summary_df['Site']==s) & (summary_df['Layer']=='root')][metric].values[0] for s in sites]\n",
    "\n",
    "    x = np.arange(len(sites))\n",
    "    width = 0.35\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, surface_vals, width, label='Surface', color='skyblue')\n",
    "    bars2 = ax.bar(x + width/2, root_vals, width, label='Root Zone', color='coral')\n",
    "\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric} by Site')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([s.replace('_', '\\n') for s in sites], fontsize=8)\n",
    "\n",
    "    if i == 0:\n",
    "        ax.legend()\n",
    "\n",
    "    # Add reference lines for good performance\n",
    "    if metric in ['R¬≤', 'NSE', 'KGE']:\n",
    "        ax.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, label='Good (0.7)')\n",
    "    elif metric in ['RMSE', 'MAE']:\n",
    "        ax.axhline(y=0.05, color='green', linestyle='--', alpha=0.5, label='Target (0.05)')\n",
    "    elif metric == 'Bias':\n",
    "        ax.axhline(y=0, color='green', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/features/validation_metrics_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved validation_metrics_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68df304f",
   "metadata": {},
   "source": [
    "## 10. Analysis and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef876625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall performance summary\n",
    "print(\"=\"*70)\n",
    "print(\"PHYSICS MODEL VALIDATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate overall metrics\n",
    "all_obs_surface = np.concatenate([obs['sm_obs_surface'].dropna().values for obs in observations.values()])\n",
    "all_pred_surface = np.concatenate([physics_results[s].loc[observations[s]['sm_obs_surface'].dropna().index, 'theta_surface'].values for s in observations.keys()])\n",
    "\n",
    "all_obs_root = np.concatenate([obs['sm_obs_root'].dropna().values for obs in observations.values()])\n",
    "all_pred_root = np.concatenate([physics_results[s].loc[observations[s]['sm_obs_root'].dropna().index, 'theta_root'].values for s in observations.keys()])\n",
    "\n",
    "overall_surface = validator.compute_metrics(all_obs_surface, all_pred_surface)\n",
    "overall_root = validator.compute_metrics(all_obs_root, all_pred_root)\n",
    "\n",
    "print(\"\\nOVERALL PERFORMANCE (All Sites Combined):\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Metric':<15} {'Surface':<15} {'Root Zone':<15}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'RMSE':<15} {overall_surface.rmse:<15.4f} {overall_root.rmse:<15.4f}\")\n",
    "print(f\"{'MAE':<15} {overall_surface.mae:<15.4f} {overall_root.mae:<15.4f}\")\n",
    "print(f\"{'Bias':<15} {overall_surface.bias:<+15.4f} {overall_root.bias:<+15.4f}\")\n",
    "print(f\"{'R¬≤':<15} {overall_surface.r_squared:<15.4f} {overall_root.r_squared:<15.4f}\")\n",
    "print(f\"{'NSE':<15} {overall_surface.nse:<15.4f} {overall_root.nse:<15.4f}\")\n",
    "print(f\"{'KGE':<15} {overall_surface.kge:<15.4f} {overall_root.kge:<15.4f}\")\n",
    "print(f\"{'N samples':<15} {overall_surface.n_valid:<15} {overall_root.n_valid:<15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE BENCHMARKS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"RMSE < 0.05 m¬≥/m¬≥  : Good for soil moisture\")\n",
    "print(\"R¬≤ > 0.70          : Strong correlation\")\n",
    "print(\"NSE > 0.50         : Acceptable model performance\")\n",
    "print(\"KGE > 0.50         : Good overall performance\")\n",
    "print(\"|Bias| < 0.02      : Low systematic error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0191e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key findings\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Best performing site\n",
    "best_site_surface = summary_df[summary_df['Layer']=='surface'].sort_values('R¬≤', ascending=False).iloc[0]\n",
    "best_site_root = summary_df[summary_df['Layer']=='root'].sort_values('R¬≤', ascending=False).iloc[0]\n",
    "\n",
    "print(f\"\\n1. Best surface layer performance: {best_site_surface['Site']} (R¬≤={best_site_surface['R¬≤']:.3f})\")\n",
    "print(f\"2. Best root zone performance: {best_site_root['Site']} (R¬≤={best_site_root['R¬≤']:.3f})\")\n",
    "\n",
    "# Sites needing improvement\n",
    "worst_site = summary_df[summary_df['Layer']=='surface'].sort_values('R¬≤').iloc[0]\n",
    "print(f\"3. Site needing most improvement: {worst_site['Site']} (R¬≤={worst_site['R¬≤']:.3f})\")\n",
    "\n",
    "# Bias analysis\n",
    "avg_bias = summary_df['Bias'].mean()\n",
    "print(f\"\\n4. Average bias across all sites: {avg_bias:+.4f} m¬≥/m¬≥\")\n",
    "if avg_bias > 0:\n",
    "    print(\"   ‚Üí Model tends to OVERESTIMATE soil moisture\")\n",
    "else:\n",
    "    print(\"   ‚Üí Model tends to UNDERESTIMATE soil moisture\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "print(\"=\"*70)\n",
    "print(\"1. Calibrate model parameters using site-specific observations\")\n",
    "print(\"2. Consider adding irrigation detection for agricultural sites\")\n",
    "print(\"3. Use ensemble of models for improved uncertainty quantification\")\n",
    "print(\"4. Validate against actual field measurements when available\")\n",
    "print(\"5. Consider seasonal calibration for regions with distinct wet/dry seasons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74194431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "output_dir = Path('../data/features')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save metrics summary\n",
    "summary_df.to_csv(output_dir / 'validation_metrics_summary.csv', index=False)\n",
    "print(f\"‚úì Saved validation_metrics_summary.csv\")\n",
    "\n",
    "# Save detailed results for each site\n",
    "for site_id in TEST_SITES.keys():\n",
    "    combined = canonical_tables[site_id].copy()\n",
    "    combined['theta_surface_physics'] = physics_results[site_id]['theta_surface']\n",
    "    combined['theta_root_physics'] = physics_results[site_id]['theta_root']\n",
    "    combined['sm_obs_surface'] = observations[site_id]['sm_obs_surface']\n",
    "    combined['sm_obs_root'] = observations[site_id]['sm_obs_root']\n",
    "\n",
    "    combined.to_csv(output_dir / f'validation_results_{site_id}.csv')\n",
    "\n",
    "print(f\"‚úì Saved individual site results\")\n",
    "print(f\"\\nAll outputs saved to: {output_dir.absolute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
